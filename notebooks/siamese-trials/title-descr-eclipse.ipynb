{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Identify Duplicate Bug Reports Using Siamese Cross-Encoder Network"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from typing import List, Dict, Tuple, Set\n",
    "import itertools"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_dataset(limit=0, verbose=False):\n",
    "  client = MongoClient()\n",
    "  db = client['eclipse']\n",
    "  bug_collection = db['clear']\n",
    "  pairs_collection = db['pairs']\n",
    "\n",
    "  pairs: Tuple[Dict] = tuple(pairs_collection.find(limit=limit))\n",
    "  if verbose:\n",
    "    print('total pairs', len(pairs))\n",
    "  bug_groups = [[pair['bug1'], pair['bug2']] for pair in pairs]\n",
    "  candidate_bug_ids = [\n",
    "    str(bug_id)\n",
    "    for bug_group in bug_groups for bug_id in bug_group\n",
    "  ]\n",
    "  if verbose:\n",
    "    print('total candidate_bug_ids', len(candidate_bug_ids))\n",
    "\n",
    "  # Storing bug reports as dictionary so that they can be\n",
    "  # retrieved by bug_id\n",
    "  bug_reports: Dict[str, Dict] = {}\n",
    "  for bug_report in bug_collection.find({'bug_id': {'$in': candidate_bug_ids}}):\n",
    "    bug_reports[bug_report['bug_id']] = bug_report\n",
    "  if verbose:\n",
    "    print('total bug_reports', len(bug_reports))\n",
    "\n",
    "  return bug_reports, pairs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def create_dataframe(bug_reports: Dict[str, Dict], pairs: Tuple[Dict]):\n",
    "  data = [\n",
    "    [\n",
    "      bug_reports[str(pair['bug1'])]['short_desc'],\n",
    "      bug_reports[str(pair['bug2'])]['short_desc'],\n",
    "      bug_reports[str(pair['bug1'])]['description'],\n",
    "      bug_reports[str(pair['bug2'])]['description'],\n",
    "      False if pair['dec'] == -1 else True]\n",
    "    for pair in pairs\n",
    "  ]\n",
    "\n",
    "  columns = ['title1', 'title2', 'description1', 'description2', 'is_similar']\n",
    "\n",
    "  return pd.DataFrame(data=data, columns=columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (100000, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                  title1  \\\n72031                FVT JVEBEANS02 - Slider orientation   \n27978                    Inner class indentation problem   \n55639                  Preference page creation problems   \n51955          Spelling errors in Committer vote e-mails   \n52145  NPE in WAR validation when creating a new J2EE...   \n3011                      Typo on Type Filters pref page   \n83607  [readme] In Variables View, values of referenc...   \n68952             TransationUnit copy constructor broken   \n90269  NPE in org.eclipse.jdt.internal.core.ExternalF...   \n69234  [perfs] Performance tests with no results shou...   \n\n                                                  title2  \\\n72031                   org.eclipse.osgi.* package names   \n27978    Does not format nicely anonymous type (1FRLTO1)   \n55639       Code Formatter Preferences Page Broken - NPE   \n51955  missing plug-ins for feature org.eclipse.stp.s...   \n52145  feature.jar's generated from update site need ...   \n3011   Linux Agent Controller initial vmsize big and ...   \n83607                 Debugging: Variable view messed up   \n68952  \"Subversive JDT ignore recommendations\" plug-i...   \n90269               NPE when refreshing external folders   \n69234  [IBD] It shoud be allowed to display propertie...   \n\n                                            description1  \\\n72031  When a slider's orientation is set to HORIZONT...   \n27978  The code shown below is formatted as shown bel...   \n55639  Using the 3.0 release candidate\\n\\nTrying to b...   \n51955  I just got an e-mail on the cdt-dev mailing li...   \n52145  Using the WTP IBuild from 6/03, an intermitten...   \n3011   The button should be named \"Disable All\" inste...   \n83607  two references point to the same object, initi...   \n68952  I broke the TranslationUnit copy constructor w...   \n90269  Build Identifier: Eclipse 3.6.0\\n\\nI am receiv...   \n69234  Using 3.3 RC1 perf tests results page: \\nhttp:...   \n\n                                            description2  is_similar  \n72031  Build M8\\n\\nThe packages in the org.eclipse.os...       False  \n27978  Formatter does not handle nicely the following...        True  \n55639  I200405290105\\n\\nSelecting the Code Formatter ...        True  \n51955  Feature org.eclipse.stp.sc.jaxws.feature_0.8.0...       False  \n52145  Created attachment 95066\\npatch to add update ...       False  \n3011   While testing with 4.3 on Red Hat I noticed th...       False  \n83607  Hi,\\n\\nthe variables view in the debugging per...        True  \n68952  Build Identifier: 20110916-0149\\n\\nI'm using S...       False  \n90269  Build Identifier: M20100909-0800\\n\\nI have a w...        True  \n69234  [IBD] It shoud be allowed to display propertie...       False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title1</th>\n      <th>title2</th>\n      <th>description1</th>\n      <th>description2</th>\n      <th>is_similar</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>72031</th>\n      <td>FVT JVEBEANS02 - Slider orientation</td>\n      <td>org.eclipse.osgi.* package names</td>\n      <td>When a slider's orientation is set to HORIZONT...</td>\n      <td>Build M8\\n\\nThe packages in the org.eclipse.os...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27978</th>\n      <td>Inner class indentation problem</td>\n      <td>Does not format nicely anonymous type (1FRLTO1)</td>\n      <td>The code shown below is formatted as shown bel...</td>\n      <td>Formatter does not handle nicely the following...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>55639</th>\n      <td>Preference page creation problems</td>\n      <td>Code Formatter Preferences Page Broken - NPE</td>\n      <td>Using the 3.0 release candidate\\n\\nTrying to b...</td>\n      <td>I200405290105\\n\\nSelecting the Code Formatter ...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>51955</th>\n      <td>Spelling errors in Committer vote e-mails</td>\n      <td>missing plug-ins for feature org.eclipse.stp.s...</td>\n      <td>I just got an e-mail on the cdt-dev mailing li...</td>\n      <td>Feature org.eclipse.stp.sc.jaxws.feature_0.8.0...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>52145</th>\n      <td>NPE in WAR validation when creating a new J2EE...</td>\n      <td>feature.jar's generated from update site need ...</td>\n      <td>Using the WTP IBuild from 6/03, an intermitten...</td>\n      <td>Created attachment 95066\\npatch to add update ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3011</th>\n      <td>Typo on Type Filters pref page</td>\n      <td>Linux Agent Controller initial vmsize big and ...</td>\n      <td>The button should be named \"Disable All\" inste...</td>\n      <td>While testing with 4.3 on Red Hat I noticed th...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>83607</th>\n      <td>[readme] In Variables View, values of referenc...</td>\n      <td>Debugging: Variable view messed up</td>\n      <td>two references point to the same object, initi...</td>\n      <td>Hi,\\n\\nthe variables view in the debugging per...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>68952</th>\n      <td>TransationUnit copy constructor broken</td>\n      <td>\"Subversive JDT ignore recommendations\" plug-i...</td>\n      <td>I broke the TranslationUnit copy constructor w...</td>\n      <td>Build Identifier: 20110916-0149\\n\\nI'm using S...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>90269</th>\n      <td>NPE in org.eclipse.jdt.internal.core.ExternalF...</td>\n      <td>NPE when refreshing external folders</td>\n      <td>Build Identifier: Eclipse 3.6.0\\n\\nI am receiv...</td>\n      <td>Build Identifier: M20100909-0800\\n\\nI have a w...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>69234</th>\n      <td>[perfs] Performance tests with no results shou...</td>\n      <td>[IBD] It shoud be allowed to display propertie...</td>\n      <td>Using 3.3 RC1 perf tests results page: \\nhttp:...</td>\n      <td>[IBD] It shoud be allowed to display propertie...</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_df = create_dataframe(*load_dataset(100000))\n",
    "print('Data shape:', dup_df.shape)\n",
    "dup_df.sample(n=10, random_state=13)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n"
     ]
    },
    {
     "data": {
      "text/plain": "title1          object\ntitle2          object\ndescription1    object\ndescription2    object\nis_similar        bool\ndtype: object"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Data Types:')\n",
    "dup_df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description of length of the feature columns\n"
     ]
    },
    {
     "data": {
      "text/plain": "              title1         title2   description1   description2\ncount  100000.000000  100000.000000  100000.000000  100000.000000\nmean       55.023020      55.052570    1456.985270    1450.559690\nstd        21.750643      21.738267    4207.950738    4231.916511\nmin         1.000000       1.000000       0.000000       0.000000\n25%        40.000000      40.000000     238.000000     240.000000\n50%        53.000000      53.000000     450.000000     450.000000\n75%        67.000000      68.000000     937.000000     942.000000\nmax       255.000000     255.000000  149346.000000  373075.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title1</th>\n      <th>title2</th>\n      <th>description1</th>\n      <th>description2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100000.000000</td>\n      <td>100000.000000</td>\n      <td>100000.000000</td>\n      <td>100000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>55.023020</td>\n      <td>55.052570</td>\n      <td>1456.985270</td>\n      <td>1450.559690</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>21.750643</td>\n      <td>21.738267</td>\n      <td>4207.950738</td>\n      <td>4231.916511</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>40.000000</td>\n      <td>40.000000</td>\n      <td>238.000000</td>\n      <td>240.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>53.000000</td>\n      <td>53.000000</td>\n      <td>450.000000</td>\n      <td>450.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>67.000000</td>\n      <td>68.000000</td>\n      <td>937.000000</td>\n      <td>942.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>149346.000000</td>\n      <td>373075.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES = ['title1', 'title2', 'description1', 'description2']\n",
    "print('Description of length of the feature columns')\n",
    "dup_df[FEATURES].apply(lambda col: col.str.len().describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers by length:\n"
     ]
    },
    {
     "data": {
      "text/plain": "            title1     title2  description1  description2\niqr      27.000000    28.0000    699.000000     702.00000\ncount  1965.000000  1545.0000  13850.000000   13914.00000\nfrac      0.001075     0.0011      0.019855       0.01995",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title1</th>\n      <th>title2</th>\n      <th>description1</th>\n      <th>description2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>iqr</th>\n      <td>27.000000</td>\n      <td>28.0000</td>\n      <td>699.000000</td>\n      <td>702.00000</td>\n    </tr>\n    <tr>\n      <th>count</th>\n      <td>1965.000000</td>\n      <td>1545.0000</td>\n      <td>13850.000000</td>\n      <td>13914.00000</td>\n    </tr>\n    <tr>\n      <th>frac</th>\n      <td>0.001075</td>\n      <td>0.0011</td>\n      <td>0.019855</td>\n      <td>0.01995</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Outliers by length:')\n",
    "\n",
    "\n",
    "def count_tail_outliers(col: pd.Series):\n",
    "  lengths: pd.Series = col.str.len()\n",
    "  iqr = lengths.quantile(0.75) - lengths.quantile(0.25)\n",
    "  outlier_range = lengths.quantile(0.75) + 1.5 * iqr\n",
    "  outlier_count = sum(lengths > outlier_range)\n",
    "  return pd.Series({\n",
    "    'iqr': iqr,\n",
    "    'count': outlier_count,\n",
    "    'frac': outlier_range / len(lengths),\n",
    "  })\n",
    "\n",
    "\n",
    "dup_df[FEATURES].apply(count_tail_outliers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "               count     frac\nis_similar                   \nFalse       296470.0  0.59294\nTrue        203530.0  0.40706",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>frac</th>\n    </tr>\n    <tr>\n      <th>is_similar</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>False</th>\n      <td>296470.0</td>\n      <td>0.59294</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>203530.0</td>\n      <td>0.40706</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_df.groupby(by='is_similar').apply(\n",
    "  lambda group: pd.Series({\n",
    "    'count': group.size,\n",
    "    'frac': len(group) / len(dup_df),\n",
    "  }),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train, Validation, Test Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_val_df, test_df = train_test_split(\n",
    "  dup_df,\n",
    "  test_size=10000,\n",
    "  stratify=dup_df.is_similar,\n",
    "  random_state=13,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "  train_val_df,\n",
    "  test_size=10000,\n",
    "  stratify=train_val_df.is_similar,\n",
    "  random_state=13,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Val Test Size: 80,000 10,000 10,000\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Val Test Size: {len(train_df):,} {len(val_df):,} {len(test_df):,}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download & Prepare Embedding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.utils as kutils\n",
    "from keras.layers.preprocessing.text_vectorization import TextVectorization\n",
    "from keras.initializers.initializers_v2 import Constant"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: , | Embedding length: 300 | Average embedding: -0.02834135199999997\n",
      "Word: the | Embedding length: 300 | Average embedding: -0.012646989333333348\n",
      "Word: . | Embedding length: 300 | Average embedding: -0.05447891\n",
      "Word: and | Embedding length: 300 | Average embedding: -0.054808682333333324\n",
      "Word: to | Embedding length: 300 | Average embedding: -0.0682633267666667\n"
     ]
    }
   ],
   "source": [
    "def ensure_glove_embedding(verbose=False):\n",
    "  import pathlib\n",
    "  embedding_data_path = kutils.get_file(\n",
    "    'glove.42B.300d.zip',\n",
    "    'https://nlp.stanford.edu/data/glove.42B.300d.zip',\n",
    "    untar=True,\n",
    "    extract=True,\n",
    "  )\n",
    "\n",
    "  # If this operation fails, print the parent-dir\n",
    "  # go there, and extract the file\n",
    "  file_path = pathlib.Path(embedding_data_path).parent / 'glove.42B.300d.txt'\n",
    "\n",
    "  if verbose:\n",
    "    with open(file_path, encoding='utf-8') as glove_embedding_file:\n",
    "      for i in range(5):\n",
    "        line = glove_embedding_file.readline()\n",
    "        word, *embedding = line.split()\n",
    "        print(\n",
    "          'Word:', word,\n",
    "          '| Embedding length:', len(embedding),\n",
    "          '| Average embedding:', sum(map(float, embedding)) / len(embedding),\n",
    "        )\n",
    "\n",
    "  return file_path\n",
    "\n",
    "\n",
    "glove_file_path = ensure_glove_embedding(verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Embedding Index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1917494 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e83b111d370244c3a2c69a90c85fe59f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1917494 words in the embedding.\n",
      "Embedding dimension: 300\n"
     ]
    }
   ],
   "source": [
    "def create_embedding_index(embedding_file_path: str, verbose=False):\n",
    "  if verbose:\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    # there are 1.9M words, and we will update progress\n",
    "    # on every 1000 word read\n",
    "    progress_bar = tqdm(total=1917494)\n",
    "\n",
    "  embedding_index: Dict[str, np.ndarray] = {}\n",
    "  with open(embedding_file_path, encoding='utf-8') as embedding_file:\n",
    "    i = 0\n",
    "    for line in embedding_file:\n",
    "      i += 1\n",
    "      word, coefficients = line.split(maxsplit=1)\n",
    "      if i > 1917494:\n",
    "        print('word:', word)\n",
    "        break\n",
    "      coefficients = np.fromstring(coefficients, 'float', sep=' ')\n",
    "      embedding_index[word] = coefficients\n",
    "\n",
    "      if verbose:\n",
    "        if i % 1000 == 0:\n",
    "          progress_bar.update(1000)\n",
    "\n",
    "  if verbose:\n",
    "    progress_bar.close()\n",
    "\n",
    "  if verbose:\n",
    "    print(f'Found {len(embedding_index)} words in the embedding.')\n",
    "    print(f'Embedding dimension: {len(next(iter(embedding_index.values())))}')\n",
    "\n",
    "  return embedding_index\n",
    "\n",
    "\n",
    "embedding_index = create_embedding_index(glove_file_path, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Vocabulary Index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "MAX_TOKENS = 20000\n",
    "MAX_TITLE_LENGTH = 100\n",
    "EMBEDDING_DIM = 300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def build_vocab(sentences: List[str], sequence_length: int):\n",
    "  vectorizer = TextVectorization(\n",
    "    max_tokens=MAX_TOKENS - 2,\n",
    "    output_sequence_length=sequence_length,\n",
    "  )\n",
    "  vectorizer.adapt(sentences)\n",
    "  vocab = vectorizer.get_vocabulary()\n",
    "  word_index = dict(zip(vocab, range(len(vocab))))\n",
    "\n",
    "  return vectorizer, word_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent title words: ['', '[UNK]', 'in', 'to', 'not']\n"
     ]
    }
   ],
   "source": [
    "title_vectorizer, title_word_index = build_vocab(\n",
    "  [*dup_df.title1, *dup_df.title2],\n",
    "  MAX_TITLE_LENGTH,\n",
    ")\n",
    "\n",
    "print(\n",
    "  'Most frequent title words:',\n",
    "  list(itertools.islice(title_word_index.keys(), 5)),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Embedding Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (20000, 300)\n",
      "Found 11764 words, missed 8234.\n"
     ]
    }
   ],
   "source": [
    "def create_embedding_matrix(\n",
    "  embedding_index: Dict[str, np.ndarray],\n",
    "  word_index: Dict[str, int],\n",
    "  verbose=False,\n",
    "):\n",
    "  hits = 0\n",
    "  misses = 0\n",
    "\n",
    "  # prepare embedding matrix\n",
    "  embedding_matrix = np.zeros((MAX_TOKENS, EMBEDDING_DIM))\n",
    "  for word, i in word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # Words not found in embedding index will be all-zeros.\n",
    "      # This includes the representation for \"padding\" and \"OOV\"\n",
    "      embedding_matrix[i] = embedding_vector\n",
    "      hits += 1\n",
    "    else:\n",
    "      misses += 1\n",
    "\n",
    "  if verbose:\n",
    "    print('Embedding shape:', embedding_matrix.shape)\n",
    "    print(f'Found {hits} words, missed {misses}.')\n",
    "\n",
    "  return embedding_matrix\n",
    "\n",
    "\n",
    "title_embedding_matrix = create_embedding_matrix(\n",
    "  embedding_index, title_word_index, True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare Training Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (80000, 100) (80000, 100) (80000,)\n",
      "Val shapes: (10000, 100) (10000, 100) (10000,)\n",
      "Test shapes: (10000, 100) (10000, 100) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def sent_vectorize(col: pd.Series):\n",
    "  return title_vectorizer(\n",
    "    np.array([[s] for s in col])\n",
    "  ).numpy()\n",
    "\n",
    "train_x1 = sent_vectorize(train_df.title1)\n",
    "train_x2 = sent_vectorize(train_df.title2)\n",
    "val_x1 = sent_vectorize(val_df.title1)\n",
    "val_x2 = sent_vectorize(val_df.title2)\n",
    "test_x1 = sent_vectorize(test_df.title1)\n",
    "test_x2 = sent_vectorize(test_df.title2)\n",
    "\n",
    "train_y = np.array(train_df.is_similar)\n",
    "val_y = np.array(val_df.is_similar)\n",
    "test_y = np.array(test_df.is_similar)\n",
    "\n",
    "print('Train shapes:', train_x1.shape, train_x2.shape, train_y.shape)\n",
    "print('Val shapes:', val_x1.shape, val_x2.shape, val_y.shape)\n",
    "print('Test shapes:', test_x1.shape, test_x2.shape, test_y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from keras.initializers.initializers_v2 import Constant"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "TitleEmbeddingLayer = layers.Embedding(\n",
    "  input_dim=MAX_TOKENS,\n",
    "  output_dim=EMBEDDING_DIM,\n",
    "  embeddings_initializer=Constant(title_embedding_matrix),\n",
    "  trainable=False,\n",
    "  name='TitleEmbeddingLayer',\n",
    ")\n",
    "\n",
    "TitleLSTMLayer = layers.Bidirectional(layers.LSTM(\n",
    "  units=100,\n",
    "  dropout=0.2,\n",
    "  recurrent_dropout=0.2,\n",
    "  return_sequences=True,\n",
    "), name='TitleBidirectionalLSTMLayer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"title_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title1_input (InputLayer)       [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title2_input (InputLayer)       [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "TitleEmbeddingLayer (Embedding) multiple             6000000     title1_input[0][0]               \n",
      "                                                                 title2_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TitleBidirectionalLSTMLayer (Bi multiple             320800      TitleEmbeddingLayer[14][0]       \n",
      "                                                                 TitleEmbeddingLayer[15][0]       \n",
      "__________________________________________________________________________________________________\n",
      "title_concat (Add)              (None, None, 200)    0           TitleBidirectionalLSTMLayer[14][0\n",
      "                                                                 TitleBidirectionalLSTMLayer[15][0\n",
      "__________________________________________________________________________________________________\n",
      "title_output (Dense)            (None, None, 1)      201         title_concat[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,321,001\n",
      "Trainable params: 321,001\n",
      "Non-trainable params: 6,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "title1_input = layers.Input(shape=(None,), dtype='int64', name='title1_input')\n",
    "title1_embedding_layer = TitleEmbeddingLayer(title1_input)\n",
    "title1_lstm_layer = TitleLSTMLayer(title1_embedding_layer)\n",
    "\n",
    "title2_input = layers.Input(shape=(None,), dtype='int64', name='title2_input')\n",
    "title2_embedding_layer = TitleEmbeddingLayer(title2_input)\n",
    "title2_lstm_layer = TitleLSTMLayer(title2_embedding_layer)\n",
    "\n",
    "title_concat = layers.Add(\n",
    "  name='title_concat'\n",
    ")([title1_lstm_layer, title2_lstm_layer])\n",
    "title_output = layers.Dense(\n",
    "  1, activation='sigmoid', name='title_output',\n",
    ")(title_concat)\n",
    "title_model = models.Model(\n",
    "  inputs=[title1_input, title2_input],\n",
    "  outputs=title_output,\n",
    "  name='title_model'\n",
    ")\n",
    "\n",
    "title_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 13/157 [=>............................] - ETA: 45:49 - loss: 0.6505 - acc: 0.6079"
     ]
    }
   ],
   "source": [
    "title_model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['acc'],\n",
    ")\n",
    "title_history = title_model.fit(\n",
    "  [train_x1, train_x2],\n",
    "  train_y,\n",
    "  batch_size=512,\n",
    "  epochs=5,\n",
    "  verbose=1,\n",
    "  validation_data=[\n",
    "    [val_x1, val_x2],\n",
    "    val_y,\n",
    "  ],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_x1[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}